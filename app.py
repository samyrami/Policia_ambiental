import pandas as pd
import streamlit as st
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.callbacks.base import BaseCallbackHandler
from html_template import logo
from langchain.document_loaders import PyPDFLoader, TextLoader
from langchain.document_loaders.csv_loader import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import re
import speech_recognition as sr
import queue

# Load environment variables
load_dotenv()

# Get API key from environment variables
API_KEY = os.getenv("OPENAI_API_KEY")
if API_KEY is None:
    st.error("Error: OPENAI_API_KEY not found in environment variables")
    st.stop()
    
st.set_page_config(page_title="EcoPoliciApp", layout="centered")



class LawDocumentProcessor:
    def __init__(self, document_directory="data", index_directory="faiss_index"):
        self.document_directory = document_directory
        self.index_directory = index_directory
        self.embeddings = OpenAIEmbeddings()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
        os.makedirs(self.document_directory, exist_ok=True)
        os.makedirs(self.index_directory, exist_ok=True)

    def load_vector_store(self):
        """Loads existing vector store"""
        index_faiss_path = os.path.join(self.index_directory, "index.faiss")
        
        # Try loading the vector store
        try:
            vector_store = FAISS.load_local(
                self.index_directory, 
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            st.success("Vector store loaded successfully!")
            return vector_store
        except Exception as e:
            st.error(f"Error loading vector store: {str(e)}")
            
            # If it fails, try to rebuild it
            st.warning("The FAISS index appears to be corrupted. Trying to rebuild it...")
            
            # Rename the problematic file for debugging
            problem_file = os.path.join(self.index_directory, "problem_index.faiss")
            if os.path.exists(problem_file):
                os.remove(problem_file)
            if os.path.exists(index_faiss_path):
                os.rename(index_faiss_path, problem_file)
            
            # Create a new index from documents
            return self.process_documents()

    def process_documents(self):
        """Procesa los documentos PDF, Excel y TXT y crea el vector store"""
        try:
            # Busca todos los tipos de archivos soportados
            pdf_files = [f for f in os.listdir(self.document_directory) if f.lower().endswith('.pdf')]
            excel_files = [f for f in os.listdir(self.document_directory) if f.lower().endswith(('.xlsx', '.xls'))]
            txt_files = [f for f in os.listdir(self.document_directory) if f.lower().endswith('.txt')]
            
            all_files = pdf_files + excel_files + txt_files
            
            if not all_files:
                st.warning("No se encontraron archivos (PDF, Excel, TXT) en el directorio data.")
                return None

            documents = []
            successful_files = []
            failed_files = []
            
            # Procesar archivos PDF
            for pdf_file in pdf_files:
                try:
                    file_path = os.path.join(self.document_directory, pdf_file)
                    
                    # Verificar si el archivo es v√°lido
                    with open(file_path, 'rb') as file:
                        header = file.read(5)
                        if header != b'%PDF-':
                            failed_files.append((pdf_file, "Encabezado PDF inv√°lido"))
                            continue
                    
                    loader = PyPDFLoader(file_path)
                    doc_pages = loader.load()
                    
                    if doc_pages:
                        documents.extend(doc_pages)
                        successful_files.append(pdf_file)
                        st.success(f"‚úÖ Procesado exitosamente: {pdf_file} ({len(doc_pages)} p√°ginas)")
                    else:
                        failed_files.append((pdf_file, "No se pudo extraer contenido"))
                
                except Exception as e:
                    failed_files.append((pdf_file, str(e)))
                    continue
            
            # Procesar archivos Excel
            for excel_file in excel_files:
                try:
                    file_path = os.path.join(self.document_directory, excel_file)
                    excel_docs = self.process_excel_file(file_path)
                    
                    if excel_docs:
                        documents.extend(excel_docs)
                        successful_files.append(excel_file)
                        st.success(f"‚úÖ Procesado exitosamente: {excel_file} ({len(excel_docs)} hojas)")
                    else:
                        failed_files.append((excel_file, "No se pudo extraer contenido"))
                
                except Exception as e:
                    failed_files.append((excel_file, str(e)))
                    continue
            
            # Procesar archivos TXT
            for txt_file in txt_files:
                try:
                    file_path = os.path.join(self.document_directory, txt_file)
                    loader = TextLoader(file_path)
                    txt_docs = loader.load()
                    
                    if txt_docs:
                        documents.extend(txt_docs)
                        successful_files.append(txt_file)
                        st.success(f"‚úÖ Procesado exitosamente: {txt_file}")
                    else:
                        failed_files.append((txt_file, "No se pudo extraer contenido"))
                
                except Exception as e:
                    failed_files.append((txt_file, str(e)))
                    continue

            # Mostrar resumen de procesamiento
            st.write("---")
            st.write("üìä Resumen de procesamiento:")
            st.write(f"- Total archivos: {len(all_files)}")
            st.write(f"- Procesados correctamente: {len(successful_files)}")
            st.write(f"- Fallidos: {len(failed_files)}")
            
            if failed_files:
                st.error("‚ùå Archivos que no se pudieron procesar:")
                for file, error in failed_files:
                    st.write(f"- {file}: {error}")

            if not documents:
                st.warning("‚ö†Ô∏è No se pudo extraer contenido de ning√∫n archivo.")
                return None

            texts = self.text_splitter.split_documents(documents)
            vectorstore = FAISS.from_documents(texts, self.embeddings)
            vectorstore.save_local(self.index_directory)
            
            st.success(f"‚úÖ Vector store creado exitosamente con {len(texts)} fragmentos de texto")
            return vectorstore
        
        except Exception as e:
            st.error(f"Error procesando documentos: {str(e)}")
            return None

def setup_retrieval_chain(vector_store):
    """Configura la cadena de recuperaci√≥n para consultas"""
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    
    retrieval_chain = ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(temperature=0),
        retriever=vector_store.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        return_source_documents=True
    )
    
    return retrieval_chain

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container
        self.text = ""
        
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)

def get_legal_context(vector_store, query):
    """Obtiene el contexto legal relevante para una consulta"""
    similar_docs = vector_store.similarity_search(query, k=5)
    context = []
    
    for doc in similar_docs:
        content = doc.page_content
        source = doc.metadata.get('source', 'Documento desconocido')
        page = doc.metadata.get('page', 'N/A')
        sheet = doc.metadata.get('sheet', None)
        
        # Extraer referencias legales espec√≠ficas
        legal_refs = re.findall(r'(?:Art√≠culo|Art\.|Ley|Decreto)\s+\d+[^\n]*', content)
        
        # Preparar informaci√≥n de la fuente
        source_info = f"{source}"
        if page != 'N/A':
            source_info += f" (P√°g. {page})"
        if sheet:
            source_info += f" (Hoja: {sheet})"
        
        context.append({
            'source': source_info,
            'content': content,
            'legal_refs': legal_refs
        })
    
    return context

SYSTEM_PROMPT = """
Eres EcoPoliciApp, un asistente especializado en legislaci√≥n ambiental colombiana, enfocado en apoyar a oficiales de la Polic√≠a Ambiental y de Carabineros.

√ÅREAS DE ESPECIALIZACI√ìN:

üêü PESCA:
- Regulaciones AUNAP
- Tallas m√≠nimas permitidas
- Vedas y restricciones

üå≥ FLORA:
- Identificaci√≥n de madera
- C√°lculo de cubitaje
- Deforestaci√≥n ilegal
- Quemas controladas

ü¶Å FAUNA:
- Tr√°fico de especies
- Manejo en desastres
- Protocolos de decomiso
- Especies protegidas

‚õèÔ∏è MINER√çA:
- Licencias y permisos
- Procedimientos de control
- Maquinaria autorizada
- Protocolos de incautaci√≥n

üåä RECURSOS H√çDRICOS:
- Contaminaci√≥n
- Vertimientos
- Protecci√≥n de cuencas

FORMATO DE RESPUESTA:

üìã PROCEDIMIENTO OPERATIVO:
‚Ä¢ [Acciones paso a paso]

‚öñÔ∏è BASE LEGAL:
‚Ä¢ [Referencias normativas espec√≠ficas]

üö® PUNTOS CR√çTICOS:
‚Ä¢ [Aspectos clave a verificar]

üîç VERIFICACI√ìN EN CAMPO:
‚Ä¢ [Lista de chequeo]

üìÑ DOCUMENTACI√ìN REQUERIDA:
‚Ä¢ [Documentos necesarios]

üëÆ COMPETENCIA POLICIAL:
‚Ä¢ [Alcance de la autoridad]

ü§ù COORDINACI√ìN INSTITUCIONAL:
‚Ä¢ [Entidades a contactar]

DIRECTRICES:
1. Priorizar seguridad del personal
2. Proteger evidencia
3. Documentar hallazgos
4. Coordinar con autoridades competentes
"""

def format_legal_context(context):
    """Formatea el contexto legal para el prompt"""
    formatted = []
    for item in context:
        refs = '\n'.join(f"‚Ä¢ {ref}" for ref in item['legal_refs']) if item['legal_refs'] else "No se encontraron referencias espec√≠ficas"
        formatted.append(f"""
        üìö Fuente: {item['source']}
        
        ‚öñÔ∏è Referencias legales:
        {refs}
        
        üí° Contexto relevante:
        {item['content'][:500]}...
        """)
    return '\n'.join(formatted)

def get_chat_response(prompt, vector_store, temperature=0.3):
    """Genera respuesta considerando el contexto legal"""
    try:
        response_placeholder = st.empty()
        stream_handler = StreamHandler(response_placeholder)
        
        # Detectar tipo de consulta
        query_type = detect_query_type(prompt)
        
        # Obtener contexto legal
        legal_context = get_legal_context(vector_store, prompt)
        
        # Construir prompt enriquecido
        enhanced_prompt = f"""
        Tipo de consulta: {query_type}
        Consulta: {prompt}
        
        Contexto legal relevante:
        {format_legal_context(legal_context)}
        
        Proporciona una respuesta estructurada seg√∫n el tipo de consulta:
        
        Para procedimientos operativos:
        - Pasos espec√≠ficos de actuaci√≥n
        - Base legal aplicable
        - Puntos cr√≠ticos de control
        - Verificaci√≥n en campo
        - Documentaci√≥n requerida
        - Competencia policial
        - Coordinaci√≥n necesaria
        
        Para consultas informativas:
        - Base legal aplicable
        - Puntos importantes
        - Referencias normativas
        """
        
        chat_model = ChatOpenAI(
            model="gpt-4o",
            temperature=temperature,
            api_key=API_KEY,
            streaming=True,
            callbacks=[stream_handler]
        )
        
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=enhanced_prompt)
        ]
        
        response = chat_model.invoke(messages)
        return stream_handler.text
            
    except Exception as e:
        st.error(f"Error generando respuesta: {str(e)}")
        return "Lo siento, ocurri√≥ un error al procesar su solicitud."

def detect_query_type(prompt):
    """Detecta el tipo de consulta para adaptar la respuesta"""
    keywords = {
        'PESCA': ['pesca', 'aunap', 'talla', 'peces'],
        'FLORA': ['madera', 'cubitaje', 'deforestaci√≥n', 'quemas'],
        'FAUNA': ['animales', 'especies', 'tr√°fico', 'decomiso'],
        'MINER√çA': ['miner√≠a', 'maquinaria', 'extracci√≥n', 'explotaci√≥n'],
        'RECURSOS_H√çDRICOS': ['agua', 'vertimientos', 'contaminaci√≥n', 'r√≠o']
    }
    
    prompt_lower = prompt.lower()
    for category, terms in keywords.items():
        if any(term in prompt_lower for term in terms):
            return category
    return 'GENERAL'

def main():
    processor = LawDocumentProcessor()
    
    # Inicializaci√≥n del vector store
    if os.path.exists(os.path.join("faiss_index", "index.faiss")):
        vector_store = processor.load_vector_store()
    else:
        st.warning("Procesando documentos legales por primera vez...")
        vector_store = processor.process_documents()
    
    if vector_store is None:
        st.error("No se pudo inicializar la base de conocimientos")
        st.stop()

    # UI Setup
    st.write(logo, unsafe_allow_html=True)
    st.title("EcoPoliciApp", anchor=False)
    st.markdown("**Asistente virtual para procedimientos ambientales y protecci√≥n de recursos naturales**")
    
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Sidebar
    with st.sidebar:
        st.markdown("""
        **Sistema de Consulta Ambiental**
        
        Tipos de consultas:
        - Informaci√≥n sobre normativa ambiental
        - Procedimientos de protecci√≥n
        - Infracciones y sanciones
        - Recomendaciones preventivas
        
        **Formatos de archivo soportados:**
        - PDF: Documentos legales, normativas, informes
        - Excel (.xlsx, .xls): Datos tabulares, registros
        - TXT: Documentos de texto plano
        """)
        
    # Chat interface
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("¬øEn qu√© puedo ayudarte?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üëÆ"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            response = get_chat_response(prompt, vector_store)
            st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()